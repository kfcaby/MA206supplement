# (Kevin) Causality {#causality}

The last few decades have seen a revolution in how statisticians view causality.  A hundred years ago, when the statistical methods students learn in introductory courses were developed, causality was considered outside the realm of statistics, except for the case of randomized controlled experiments. In other words, statistics could only answer questions of association, but not of causality.  However, this limited view of statistics was at odds with their usage in every day research.  For example, the greatest public health triumph of the 20th century was the reduction in cigarette smoking, which exploded after World War II with their mass production and marketing.  The statistical evidence of the health effects of smoking comes entirely from observational studies -- there has never been a randomized controlled trial for smoking.  The American Cancer Society's observational studies of the 1960's and 1970's were huge undertakings and provided compelling evidence of the harmful effects of cigarette smoking.  Clearly, statistical theory and practice had diverged in their understandings of causality.

However, in the 1980's and 1990's, researchers in different disciplines began revisiting causality.  They developed mathematical language for expressing causation, which cannot be uniquely expressed using the traditional language of association. In addition, they showed that randomized controlled trials are special cases of when the researcher has full knowledge of the assignment mechanism.  The assignment mechanism is the process in which subjects are assigned to different levels of the treatment.  Lastly, they showed that causal effects could be estimated from observational studies under a wide variety of circumstances when the assignment mechanism is known.  Today, while "correlation does not imply causation" is still useful advice when assessing causal claims in observational studies, statistical theory and practice suggest our assessment of causal claims in observational studies should be much richer and nuanced than this simple rule of thumb.

(add citations)

## What does it mean for one thing to cause another

We say one variable (the treatment or intervention) *causes* another variable (the outcome) if there is a change in the average outcome between subjects when they receive the treatment and the same subjects when they do not receive the treatment.  This definition differs from *association*, which is a change in the average outcome between subjects who received the treatment and different subjects who did not receive the treatment.  Thus, causation is a comparison of observed outcomes and their counterfactuals ("what would have happened if the subject were in the other treatment group").

Unfortunately, we cannot observe both outcomes for subjects in most cases.  For example, when estimating the effect of smoking on long term health outcomes, it is impossible to observe the same subject as a smoker and as a nonsmoker.  We only get to observe one of the outcomes.  However, under certain circumstances, we can obtain good estimates of effects without observing both outcomes for each individual.  The most famous of these is the randomized controlled experiment.

(add see and do from Pearl here?)

## Randomized controlled experiments

One of the most important scientific discoveries of the early 20th century was the randomized controlled trial (RCT).  In the simplest form of RCTs, researchers randomly assign subjects to receive the treatment or to be in the control group. If they observe a difference in average outcomes between the two groups, then we would say the treatment caused the outcome. *Why does assigning subjects to groups by the simple action of flipping a coin result in such a radical difference in how we interpret the results?* The answer lies in the definition of causation above.  Causation compares the outcomes between the same subjects. When we randomize the treatment, we end up comparing the outcomes between one group of subjects with the treatment and another group of subjects without the treatment who we expect to be very similar.  In fact, when we have large enough sample sizes, it would be very unusual for the two groups to differ much.  The two groups are *exchangeble*.  In other words, we would expect the control group to have had similar results as the treatment group if they were the treatment group, and vice versa.      

However, this important discovery led to the overly restrictive view that causality can only be shown with RCTs. Unfortunately, RCTs are not always ethical, feasible, or desirable.  Imagine enrolling in a study where you could be randomly assigned to be a smoker for the next 20 years.  Towards the end of the 20th century, researchers began taking a more expansive view of causality in observational studies.    

## Observational Studies and Confounding

In observational studies, researchers do not intervene on the assignment of subjects to treatment and control groups. (Note: a common misconception is that observational studies do not have treatment and control groups.) Instead, other factors determine which group subjects are assigned to and the assignment mechanism is more complex.  Confounding occurs when factors determining assignment to treatment groups are also causes of the outcome.  In other words, the treatment and control groups are fundamentally different in ways that are important to the outcome. For example, smokers are more likely to be male and have less education. Being male and having less education are important causes of many long term health outcomes.  If we observe an association between smoking and a health outcome without accounting for sex and education, we cannot distinguish the effect of smoking from the effect of sex and education.  Confounding is a form of statistic bias; estimates of the treatment effect using the observed association will be systemically off, regardless of the sample size.  

## Causal Diagrams


