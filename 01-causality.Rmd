# (Kevin) Causality {#causality}

The last few decades have seen a revolution in how statisticians view causality.  A hundred years ago, when the statistical methods students learn in introductory courses were developed, causality was considered outside the realm of statistics, except for the case of randomized controlled experiments. In other words, statistics could only answer questions of association, but not of causality.  However, this limited view of statistics was at odds with its usage in every day research.  For example, the greatest public health triumph of the 20th century was the reduction in cigarette smoking, which exploded after World War II with their mass production and marketing.  The statistical evidence of the health effects of smoking comes entirely from observational studies -- there has never been a randomized controlled trial for smoking.  The American Cancer Society's observational studies of the 1960's and 1970's were huge undertakings and provided compelling evidence of the harmful effects of cigarette smoking.  Clearly, statistical theory and practice had diverged in their understandings of causality.

However, in the 1980's and 1990's, researchers in different disciplines began revisiting causality.  They developed mathematical language for expressing causation, which cannot be uniquely expressed using the traditional language of association. In addition, they showed that randomized controlled trials are special cases of more general situations when the researcher has full knowledge of the assignment mechanism.  The *assignment mechanism* is the process in which subjects are assigned to different levels of the treatment.  Lastly, they showed that causal effects could be estimated from observational studies under a wide variety of circumstances when the assignment mechanism is known.  Today, while "correlation does not imply causation" is still useful advice when assessing causal claims in observational studies, statistical theory and practice suggest our assessment of causal claims in observational studies should be much richer and nuanced than this simple rule of thumb.

(add citations)

## What does it mean for one thing to cause another

We say one variable (the treatment or intervention) *causes* another variable (the outcome) if there is a change in the average outcome between subjects when they receive the treatment and the same subjects when they do not receive the treatment.  This definition differs from *association*, which is a change in the average outcome between subjects who received the treatment and different subjects who did not receive the treatment.  Thus, causation is a comparison of observed outcomes and their counterfactuals ("what would have happened if the subject were in the other treatment group").

Unfortunately, in most cases, we cannot observe both outcomes for subjects.  For example, when estimating the effect of smoking on long term health outcomes, it is impossible to observe the same subject as a smoker and as a nonsmoker.  We only observe one of the outcomes.  However, under certain circumstances, we can obtain good estimates of effects without observing both outcomes for each individual.  The most famous of these is the randomized controlled experiment.

(add see and do from Pearl here?)

## Randomized controlled experiments

One of the most important scientific discoveries of the early 20th century was the randomized controlled trial (RCT).  In its simplest form, researchers randomly assign subjects to receive the treatment or be in the control group. If they observe a difference in average outcomes between the two groups, then we would say the treatment caused the outcome. *Why does assigning subjects to groups by the simple action of flipping a coin result in such a radical difference in how we interpret the results?* The answer lies in the definition of causation above.  Causation compares the outcomes between the same subjects. When we randomize the treatment, we end up comparing the outcomes between one group of subjects with the treatment and another group of subjects without the treatment who we expect to be very similar.  In fact, when we have large enough sample sizes, it would be very unusual for the two groups to differ much.  We refer to the two groups as *exchangeble*.  In other words, we would expect the control group to have had similar results as the treatment group if they were the treatment group, and vice versa.      

However, an overly restrictive view of causality followed this important discovery.  That is, causality can *only* be shown with RCTs.  This placed a huge limitation on the types of research questions statistics could address. Frequently, RCTs are not ethical, feasible, or desirable.  Imagine enrolling in a study where you could be randomly assigned to be a smoker for the next 20 years.  Towards the end of the 20th century, researchers began taking a more expansive view of causality in observational studies.    

## Observational Studies and Confounding

In observational studies, researchers do not intervene on the assignment of subjects to treatment and control groups. (Note: a common misconception is that observational studies do not have treatment and control groups. This is not true.  It is about how subjects are *assigned* to the treatment groups.) Instead, other factors determine subjects' group (treatment or control) assignment.  Confounding occurs when these other factors determining assignment are themselves causes of the outcome.  In other words, the treatment and control groups are different in ways that are important to the outcome. The two groups are not exchangeable.  An observed association between the treatment and outcome could mean (1) the treatment caused the outcome, (2) other factors causing group assignment caused the outcome, or (3) both.  Furthermore, with only information on the treatment and outcome, it is not possible to identify which of the three is the correct explanation.  Confounding is a form of statistical bias -- using the observed association as an estimate of the treatment effect will be systemically off.  Increasing the sample size does not help fix bias, you just get a more precise, wrong estimate.

For example, consider an observational study investigating long term health effects of smoking.  In many populations, males are more likely to be smokers. In addition, males have different risks for long term health outcomes than females, regardless of whether they smoke.  If we observe an association between smoking and an outcome without information on sex, we cannot distinguish the effect of smoking from the effect of sex.  

However, researchers in the late 20th century had a key insight.  If we know the assignment mechanism and measure a sufficient set of confounding variables, you can obtain good estimates of treatment effects from observational studies.  This was huge! Observational studies and RCTs are not fundamentally different. Estimating effects requires understanding the assignment mechanism, and RCTs are just a special case with a simple, known assignment mechanism.   Given this insight, researchers became more comfortable making causal claims from observational studies when they have knowledge of the assignment mechanism. *How do we identify a sufficient set of confounding variables?* For that question, we turn to causal diagrams. 


## Causal Diagrams


Causal diagrams are useful tools for depicting the assignment mechanism.  In many cases, following simple heuristics will identify a sufficient set of confounding variables to measure and control for.   