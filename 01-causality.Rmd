# Causality {#causality}

The last few decades have seen a revolution in how statisticians view causality.  A hundred years ago, when the statistical methods students learn in introductory courses were developed, causality was considered outside the realm of statistics, except for the case of randomized controlled experiments. In other words, statistics could only answer questions of association, but not of causality.  However, this limited view of statistics was at odds with its usage in every day research.  For example, the greatest public health triumph of the 20th century was the reduction in cigarette smoking, which exploded after World War II with their mass production and marketing.  The statistical evidence of the health effects of smoking comes entirely from observational studies -- there has never been a randomized controlled trial for smoking.  The [American Cancer Society's observational studies](https://www.cancer.org/latest-news/the-study-that-helped-spur-the-us-stop-smoking-movement.html) beginning in the 1950's were huge undertakings and provided compelling evidence of the harmful effects of cigarette smoking [@hammond1954relationship;@hammond1966smoking].   Clearly, statistical theory and practice had diverged in their understandings of causality.

(add more citations)

However, in the 1980's and 1990's, researchers in different disciplines began revisiting causality [@greenland1986identifiability].  They developed mathematical language for expressing causation, which cannot be uniquely expressed using the traditional language of association. In addition, they showed that randomized controlled trials are special cases of more general situations when the researcher has full knowledge of the assignment mechanism.  The *assignment mechanism* is the process in which subjects are assigned to different levels of the treatment.  Lastly, they showed that causal effects could be estimated from observational studies under a wide variety of circumstances when the assignment mechanism is known.  Today, while "correlation does not imply causation" is still useful advice when assessing causal claims in observational studies, statistical theory and practice suggest our assessment of causal claims in observational studies should be much richer and nuanced than this simple rule of thumb.

(add citations)

## What does it mean for one thing to cause another

We say one variable (the treatment or intervention) *causes* another variable (the outcome) if there is a change in the average outcome between subjects when they receive the treatment and the same subjects when they do not receive the treatment.  This definition differs from *association*, which is a change in the average outcome between subjects who received the treatment and different subjects who did not receive the treatment.  Thus, causation is a comparison of observed outcomes and their counterfactuals ("what would have happened if the subject were in the other treatment group").

Unfortunately, in most cases, we cannot observe both outcomes for subjects.  For example, when estimating the effect of smoking on long term health outcomes, it is impossible to observe the same subject as a smoker and as a nonsmoker.  We only observe one of the outcomes.  However, under certain circumstances, we can obtain good estimates of effects without observing both outcomes for each individual.  The most famous of these is the randomized controlled experiment.

(add see and do from Pearl here?)

## Randomized controlled experiments

One of the most important scientific discoveries of the early 20th century was the randomized controlled trial (RCT).  In its simplest form, researchers randomly assign subjects to receive the treatment or be in the control group. If they observe a difference in average outcomes between the two groups, then we would say the treatment caused the outcome. *Why does assigning subjects to groups by the simple action of flipping a coin result in such a radical difference in how we interpret the results?* The answer lies in the definition of causation above.  Causation compares the outcomes between the same subjects. When we randomize the treatment, we end up comparing the outcomes between one group of subjects with the treatment and another group of subjects without the treatment who we expect to be very similar.  In fact, when we have large enough sample sizes, it would be very unusual for the two groups to differ much.  We refer to the two groups as *exchangeble*.  In other words, we would expect the control group to have had similar results as the treatment group if they were the treatment group, and vice versa.      

However, an overly restrictive view of causality followed this important discovery.  That is, causality can *only* be shown with RCTs.  This placed a huge limitation on the types of research questions statistics could address. Frequently, RCTs are not ethical, feasible, or desirable.  Imagine enrolling in a study where you could be randomly assigned to be a smoker for the next 20 years.  Towards the end of the 20th century, researchers began taking a more expansive view of causality in observational studies.    

## Observational Studies and Confounding

In observational studies, researchers do not intervene on the assignment of subjects to treatment and control groups. (Note: a common misconception is that observational studies do not have treatment and control groups. This is not true.  It is about how subjects are *assigned* to the treatment groups.) Instead, other factors determine subjects' group (treatment or control) assignment.  Confounding occurs when these other factors determining assignment are themselves causes of the outcome.  In other words, the treatment and control groups are different in ways that are important to the outcome. The two groups are not exchangeable.  An observed association between the treatment and outcome could mean (1) the treatment caused the outcome, (2) other factors causing group assignment caused the outcome, or (3) both.  Furthermore, with only information on the treatment and outcome, it is not possible to identify which of the three is the correct explanation.  Confounding is a form of statistical bias -- using the observed association as an estimate of the treatment effect will be systemically off.  Increasing the sample size does not help fix bias, you just get a more precise, wrong estimate.

For example, consider an observational study investigating long term health effects of smoking.  In many populations, males are more likely to be smokers. In addition, males have different risks for long term health outcomes than females, regardless of whether they smoke.  If we observe an association between smoking and an outcome without information on sex, we cannot distinguish the effect of smoking from the effect of sex.  

However, researchers in the late 20th century had a key insight.  If we know the assignment mechanism and measure a sufficient set of confounding variables, you can obtain good estimates of treatment effects from observational studies.  This was huge! Observational studies and RCTs are not fundamentally different. Estimating effects requires understanding the assignment mechanism, and RCTs are just a special case with a simple, known assignment mechanism.   Given this insight, researchers became more comfortable making causal claims from observational studies when they have knowledge of the assignment mechanism. *How do we identify a sufficient set of confounding variables?* For that question, we turn to causal diagrams. 

(discuss well-defined interventions?)

## Causal Diagrams

Causal diagrams are useful tools for depicting the assignment mechanism (also called the causal model). Experts use subject matter knowledge in their field to specify the causal model.  They typically specify the causal model prior to collecting data to identify confounding variables to measure.  Importantly, there is no way to determine the presence of unmeasured confounding using the data.  In addition, using simple heuristics for causal diagrams, they identify a sufficient set of confounding variables to control for during design and analysis.   

Causal diagrams are directed, acyclic graphs (DAGs) where the nodes are variables and a directed edge (arrow) connecting two nodes indicates the node at the arrow's tail is a cause of the node at the arrow's head.  The graphs are directed because the arrows point in one direction.  They are acyclic because you can never get back to where you started by following arrows.  The convention in many disciplines is to order the variables temporally from left to right -- we adopt that convention here.  

There are three building blocks of causal diagrams.

### Confounding variable

Figure \@ref(fig:confounder) depicts the confounding variable $C$ of the effect of treatment $X$ on outcome $Y$.  We will observe an association between $X$ and $Y$ even if there is no treatment effect. The levels of $X$ differ in terms of $C$ and $C$ itself is a cause of $Y$. Without measuring and controlling for $C$, we cannot distinguish the effect of $X$ on $Y$ from the association through confounding variable $C$.  However, if $C$ is the only confounding variable, controlling for it will result in good estimates of the effect of $X$ on $Y$.  

(backdoor path)

![(#fig:confounder) A confounding variable $C$ on the effect of $X$ on $Y$.](./images/confounder.png)

For example, let's say researchers investigate the effect of a master's degree on adult earnings.  They survey a large number of individuals and record whether they have a master's degree and their earnings. Socioeconomic status is a confounding variable.  Individuals with higher socioeconomic status are more likely to earn master's degrees.  In addition, they are more likely to have higher adult earnings, regardless of whether they have a master's degree.  For this example, let's assume socioeconomic status is the only confounding variable.  If the researchers observe an association between master's degrees and earnings without information on socioeconomic status, it is not possible to determine if the association is due to an effect of master's degrees or the effect of socioeconomic status.   

### Collider

Figure \@ref(fig:collider) depicts treatment $X$ with no effect on outcome $Y$. $X$ and $Y$ are both causes of collider $Z$ (the two incoming arrows *collide*).  The box around $Z$ indicates conditioning upon $Z$ in the analysis.  In this case, there will be an association between $X$ and $Y$ even though there is no treatment effect.  Figure \@ref(fig:collider) is a common way to depict *selection bias* where an association in subjects selected for the study is not present in the general population.  In the selection bias diagram, $Z$ is an indicator of selection into the study with a box around it because researchers only observe subjects selected into the study.  

![(#fig:collider) Collider $Z$ with no treatment effect of $X$ on $Y$.](./images/collider.png)

A very famous example appears in @pearl2018book.  In the general population, we would not expect to see an association between an individual's talent and looks.  More talented people are not better looking and vice versa.  However, if we look only at famous Hollywood actors ($Z$), we would see an association between talent and looks in this group because an individual needs either talent or looks (or both) to become a famous Hollywood actor.  More seriously, *selection bias* is a huge issue in medical and public health studies resulting in easily misinterpretated associations [@hernan2004structural;@cole2010illustrating;@elwert2014endogenous].

### Mediator

Figure \@ref(fig:mediator) depicts mediator $M$ of the effect of treatment $X$ on outcome $Y$.  In this case, $X$ is a cause of $M$, $M$ is a cause of $Y$, and there is no effect of $X$ on $Y$ that cannot be explained by the effect of $M$ on $Y$.  A common mistake is to adjust for $M$.  If $M$ is categorical, we will not observe an association between $X$ and $Y$ within levels of $M$.  However, there is still an effect of $X$ on $Y$.  

![(#fig:mediator) Mediator $M$ of the effect of treament $X$ on outcome $Y$.](./images/mediator.png)

For example, let's say researchers are investigating an adverse reaction to a medication using a treatment group and a control group where the adverse reactions are always preceded by increased blood pressure.  Even if there is an effect of the medication on the adverse reason, when we condition upon experiencing increased blood pressure, we will not observe an association between the medication and adverse reactions.

Unfortunately, some researchers condition upon everything that they measure, often resulting in poor estimates of effects [@hernan2002causal].